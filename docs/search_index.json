[
["diag1.html", "9 Diagnósticos parte I Residuales Ejemplo Supuestos Chequeando normalidad de los errores \\(e_i\\) Chequeando si errores \\(e_i\\) con media cero Chequeando si los errores \\(e_i\\) tiene varianza constante Chequeando si errores \\(e_i\\) no están correlacionados Gráficos de residuales usando car", " 9 Diagnósticos parte I En este capítulo se presentan varias herramientas útiles para hacer diagnósticos de un modelo ajustado. Residuales Los residuales en los modelos de regresión nos ayuda a: determinar qué tan bien el modelo explica el patrón de los datos, verificar el cumplimiento de los supuestos del modelo. A continuación se muestran los diferentes tipos de residuales que se pueden definir para un modelo de regresión. La cantidad \\(w_i\\) corresponde al peso o importancia de cada observación en el modelo, por defecto es \\(w_i=1\\). La cantidad \\(h_{ii}\\) se llama leverage y corresponde al elemento \\(i\\) de la diagonal de la matriz sombrero o hat \\(\\boldsymbol{H} = \\boldsymbol{X}(\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1}\\boldsymbol{X}^\\top\\). La varianza \\(\\hat{\\sigma}_{(i)}^{2}\\) es la varianza estimada al NO tener en cuenta la observación \\(i\\)-ésima. La cantidad \\(\\hat{y}_{(i)}\\) es la estimación de la \\(i\\)-ésima observación usando un modelo en el cual la observación \\(i\\)-ésima NO fue usada en el ajuste del modelo. Para obtener los residuales arriba definidos tenemos las siguientes funciones: residuals(object, type=c(&quot;working&quot;, &quot;response&quot;, &quot;deviance&quot;, &quot;pearson&quot;, &quot;partial&quot;)) rstandard(model) rstudent(model) Si un modelo lineal está correctamente especificado (ajustado), los residuos de Pearson serán independientes de los valores ajustados e independientes de los predictores, y estos gráficos deben ser “gráficos nulos”, es decir, gráficos sin características sistemáticas, en el sentido de que la distribución condicional de los residuos (en el eje vertical del gráfico) no debe cambiar con los valores ajustados o con un predictor (en el eje horizontal) (Fox and Weisberg 2019). Ejemplo Considere los datos mostrados abajo, ajuste un modelo de regresión lineal para explicar la media de \\(y\\) en función de \\(x\\) y usando como pesos los valores de \\(w\\). Obtenga los residuales usando las definiciones y luego usando las funciones de R, compruebe que los resultados coinciden. x &lt;- c(4, 6, 8, 7, 8, 5) y &lt;- c(1, 2, 3, 4, 5, 4) w &lt;- c(0.1, 0.1, 0.2, 0.1, 0.2, 0.9) Solución Primero se van a calcular los residuales manualmente aplicando las definiciones. mod &lt;- lm(y ~ x, weights=w) ei &lt;- y - fitted(mod) pi &lt;- ei * sqrt(mod$weights) hii &lt;- lm.influence(mod)$hat di &lt;- ei * sqrt(mod$weights) / sqrt(summary(mod)$sigma^2 * (1-hii)) ri &lt;- ei * sqrt(mod$weights) / sqrt(lm.influence(mod)$sigma^2 * (1-hii)) cbind(ei=ei, pi=pi, di=di, ri=ri) ## ei pi di ri ## 1 -2.3487395 -0.74273664 -1.36444485 -1.61615603 ## 2 -1.7100840 -0.54077605 -0.92897379 -0.90846102 ## 3 -1.0714286 -0.47915742 -1.05401601 -1.07406432 ## 4 0.1092437 0.03454589 0.06072186 0.05261092 ## 5 0.9285714 0.41526977 0.91348054 0.88927302 ## 6 0.4705882 0.44643920 1.63607317 2.46342873 Ahora se van a calcular los residuales usando las funciones de R. cbind(ei=residuals(mod, type=&#39;working&#39;), pi=residuals(mod, type=&#39;pearson&#39;), di=rstandard(mod), ri=rstudent(mod)) ## ei pi di ri ## 1 -2.3487395 -0.74273664 -1.36444485 -1.61615603 ## 2 -1.7100840 -0.54077605 -0.92897379 -0.90846102 ## 3 -1.0714286 -0.47915742 -1.05401601 -1.07406432 ## 4 0.1092437 0.03454589 0.06072186 0.05261092 ## 5 0.9285714 0.41526977 0.91348054 0.88927302 ## 6 0.4705882 0.44643920 1.63607317 2.46342873 Estimado lector, ¿qué puede usted concluir de los resultados de este ejemplo? Supuestos Los supuestos en un modelo de regresión se pueden escribir de dos formas: Forma I Los errores \\(e_i\\) tienen distribución normal. Los errores \\(e_i\\) tienen media cero. Los errores \\(e_i\\) tiene varianza constante. Los errores \\(e_i\\) no están correlacionados. Forma II La respuesta \\(y\\) tiene distribución normal. La varianza de la respuesta \\(y\\) es constante. Las observaciones son independientes \\(y\\). Relación lineal entre la variable respuesta y las covariables. Ambos conjuntos de supuestos son equivalentes, la forma I está dirigida hacia los \\(e_i\\) mientras que en la forma II está dirigida hacia los \\(y_i\\). Chequeando normalidad de los errores \\(e_i\\) Para estudiar si lo errores \\(e_i\\) tienen una distribución aproximadamente normal se construyen los residuales estandarizados \\(d_i\\). Una vez calculados los \\(d_i\\) se construye un gráfico de normalidad o qqplot usando la función qqnorm, el resultado es un gráfico similar al mostrado a continuación. En la siguiente figura se muestran los diferentes patrones que se pueden encontrar en el gráfico de normalidad para \\(d_i\\). Para que se cumpla el supuesto de normalidad de los errores \\(e_i\\) se necesita que los \\(d_i\\) estén lo más alineados con la recta de referencia, alejamientos severos de esta recta significa que se viola el supuesto de normalidad de \\(e_i\\). Chequeando si errores \\(e_i\\) con media cero Para determinar si los errores \\(e_i\\) tienen una media cerca al valor de cero se puede usar la función mean sobre los residuales. Chequeando si los errores \\(e_i\\) tiene varianza constante En la siguiente figura se muestra el caso de varianza \\(\\sigma^2\\) constante u homocedasticidad y el caso de varianza \\(\\sigma^2\\) no constante o heterocedasticidad. La homocedasticidad es el supuesto exigido en modelos de regresión. Para chequear si los errores \\(e_i\\) tiene varianza constante se construye un gráfico de \\(e_i\\) versus \\(\\hat{\\mu}_i\\), un gráfico similar al mostrado a continuación. En la siguiente figura se muestran los diferentes patrones que se pueden encontrar en el gráfico de \\(e_i\\) versus \\(\\hat{\\mu}_i\\). Para que se cumpla el supuesto de homocedasticidad se necesita que los puntos se ubiquen como una nube de puntos sin ningún patrón claro. Cualquier patrón que se observe es evidencia de que no se cumple el supuesto de homocedasticidad. Una analogía útil para recordar si se cumple la homocedasticidad es que el gráfico de \\(e_i\\) versus \\(\\hat{\\mu}_i\\) tenga una apariencia como la mostrada en la siguiente figura. Otro gráfico útil para chequear el supuesto de homocedasticidad es dibujar un diagrama de dispersión de \\(\\sqrt{|d_i|}\\) versus \\(\\hat{\\mu}_i\\), un gráfico similar al mostrado a continuación. Al igual que en el gráfico de \\(e_i\\) versus \\(\\hat{\\mu}_i\\), se espera que no existan patrones claros en la nube de puntos. Chequeando si errores \\(e_i\\) no están correlacionados Para estudiar esta situación se debe tener la historia de los errores, es decir, el orden en que las observaciones fueron tomadas. Usando es información se puede dibujar un diagrama de dispersión del residual versus tiempo, un gráfico similar al mostrado a continuación. En la siguiente figura se muestran los diferentes patrones que se pueden encontrar en el gráfico de \\(e_i\\) versus el tiempo. Para que se cumpla el supuesto de independencia se espera que los puntos se ubiquen como una nube de puntos sin ningún patrón claro. Ejemplo En este ejemplo vamos a simular 500 observaciones del modelo mostrado abajo, luego vamos a ajustar un modelo correcto a los datos y por último vamos a realizar el análisis de residuales para saber si el modelo fue bien ajustado. \\[\\begin{align*} y_i &amp;\\sim N(\\mu_i, \\sigma^2) \\\\ \\mu_i &amp;= 4 - 6 x_i \\\\ x_i &amp;\\sim U(-5, 6) \\\\ \\sigma^2 &amp;= 16 \\end{align*}\\] Solución Lo primero que se debe hacer es simular los datos y ajustar el modelo. gen_dat &lt;- function(n) { varianza &lt;- 16 x &lt;- runif(n=n, min=-5, max=6) media &lt;- 4 - 6 * x y &lt;- rnorm(n=n, mean=media, sd=sqrt(varianza)) marco_datos &lt;- data.frame(y=y, x=x) return(marco_datos) } datos &lt;- gen_dat(n=500) mod &lt;- lm(y ~ x, data=datos) Los gráficos de residuales explicados anteriormente se pueden obtener usando la función plot sobre el modelo ajustado mod. par(mfrow=c(2, 2)) plot(mod, las=1, col=&#39;deepskyblue4&#39;, which=1:3) En la figura anterior se observa que los puntos del gráfico de normalidad de los residuales estandarizados \\(d_i\\) están muy cerca de la línea de referencia. Los diagramas de dispersión entre los residuales versus \\(\\hat{\\mu}_i\\) no muestran ninguna anomalía. Por estas razones podemos asumir que los supuestos del modelo se cumplen. En este ejemplo se usó plot(mod, which=1:3) para obtener los tres primeros gráficos que entrega la función plot, el cuarto gráfico no es un gráfico de residuales y por eso se evitó en el ejemplo. Reto para el lector Use la información del ejemplo anterior y viole alguno de los supuestos dentro de la función gen_dat o al momento de ajustar el modelo con lm. Luego construya los gráficos de residuales y compruebe que los gráficos le indicarán que algo no está bien en el modelo ajustado. Gráficos de residuales usando car El paquete car de Fox, Weisberg, and Price (2020), tiene unas funciones especiales para crear otro tipo de gráficos de residuales y que son útiles para identificar posibles anomalías en el modelo ajustado. A continuación las funciones para crear nuevos gráficos de residuales. residualPlots(model): dibuja una gráfica de los residuos de Pearson versus cada término del predictor lineal y los valores ajustados \\(\\hat{\\mu}_i\\). También entrega hace una prueba de hipótesis de curvatura para cada una de las gráficas agregando un término cuadrático y probando si se necesita el término cuadrático o no. mmps o marginalModelPlots(model): dibuja una gráfica de la respuesta \\(y_i\\) versus cada covariable cuantitativa y los valores ajustados \\(\\hat{\\mu}_i\\), es una variación la propuesta de Cook and Weisberg (1997). Ejemplo Este ejemplo corresponde al ejemplo mostrado en el capítulo 6 de Fox and Weisberg (2019). En este ejemplo se desea ajustar un modelo de regresión para explicar la media de la variable prestige en función de las variables education, income y type, usando la base de datos Prestige del paquete car (Fox, Weisberg, and Price 2020). library(car) prestige_mod1 &lt;- lm (prestige ~ education + income + type, data=Prestige) Para construir los gráficos de los residuos de Pearson versus cada término del predictor lineal y los valores ajustados \\(\\hat{\\mu}_i\\) se usa la siguiente instrucción (las=1 para poner los números vertical en el eje Y). residualPlots(prestige_mod1, las=1) ## Test stat Pr(&gt;|Test stat|) ## education -0.6836 0.495942 ## income -2.8865 0.004854 ** ## type ## Tukey test -2.6104 0.009043 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 De la figura anterior se observa lo siguiente: El gráfico de residuales vs education se asemeja a un “gráfico nulo”, en la que ningún patrón particular es aparente. El gráfico de residuales vs income presenta una curvatura. El gráfico de residuales vs type (var. cuali.) presenta una apariencia de un “gráfico nulo”, todas las cajas con a proximadamente el mismo centro y extensión. De las observaciones anteriores parece que falta el término \\(Income^2\\) en el predictor lineal. La sospecha de que falta el término \\(Income^2\\) se ve reforzada por la tabla que acompaña la salida de residualPlots(prestige_mod). En la línea para la variable income se tiene la prueba de hipótesis \\(H_0:\\) no se necesita \\(Income^2\\) versus \\(H_A:\\) si se necesita \\(Income^2\\). El valor-P de esta prueba es 0.004854 y por lo tanto se justifica incluir \\(Income^2\\). Para dibujar los gráficos marginales de \\(y_i\\) versus cada covariable cuantitativa y los valores ajustados \\(\\hat{\\mu}_i\\) se usa la siguiente instrucción. marginalModelPlots(prestige_mod1, las=1) ## Warning in mmps(...): Interactions and/or factors skipped La línea de color azul es una regresión lowess entre \\(y_i\\) y la variable que está en el eje horizontal. La línea de color rojo es una regresión lowess entre \\(\\hat{\\mu}_i\\) y la variable que está en el eje horizontal. Según Fox and Weisberg (2019), si el modelo se ajusta bien a los datos, las líneas (azul y roja) estarán próximas, por el contrario, si las líneas difieren demasiado, es evidencia de que el modelo no explica bien los datos. De la figura anterior se observa que las líneas (azul y roja) difieren un poco en el panel de \\(y_i\\) versus income, eso refuerza lo observado antes de que sería bueno agregar un término I(income^2). prestige_mod2 &lt;- lm (prestige ~ education + income + I(income^2) + type, data=Prestige) residualPlots(prestige_mod2, las=1) ## Test stat Pr(&gt;|Test stat|) ## education -0.3844 0.70156 ## income 0.3909 0.69680 ## I(income^2) 2.1493 0.03426 * ## type ## Tukey test -2.1877 0.02869 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 anova(prestige_mod1, prestige_mod2) ## Analysis of Variance Table ## ## Model 1: prestige ~ education + income + type ## Model 2: prestige ~ education + income + I(income^2) + type ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 93 4681.3 ## 2 92 4292.5 1 388.74 8.3317 0.004854 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 References "]
]
